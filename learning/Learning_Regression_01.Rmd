---
title: "Learning Regression"
author: "Nate Breznau"
date: "7/12/2021"
output: html_document
---

TO DO:

Nate - use the check_model function with equatiomatic https://easystats.github.io/performance/reference/check_model.html



```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

pacman::p_load("tidyverse", # suite of packages that all work together
               "ggplot2", # recommended plotting package
               "tidylog", # a package that outputs a log of data transformations after each command (like what Stata does)
               "equatiomatic", # a package that displays equations from a previously called function
               "kableExtra", # a package for making clean looking tables
               "jtools", #good for summarizing and visualizing regression results
               "ggpubr",
               "countrycode", # for automatically recoding country names and codes
               "lme4") # for multilevel modeling
```

Helpful notes from R Studio:

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

### Load Data

These data are a cumulation of all ISSP surveys that asked the question:

*"It is the responsibility of the government to reduce the differences in income between people with high incomes and those with low incomes."*

```{r data}
load(here::here("data","socstat.Rda"))

# add country labels
df <- df %>%
  mutate(iso3c = countrycode(cntry, "iso3n", "iso3c"))
```

#### Descriptive ('Browsing Variables')

Often we look at descriptive statistics before proceeding with analysis.

##### Historgrams of Dependent Variables

Call them "dependent" here because they are our primary variables of interest.



```{r desc}

hist(df$incdiff)
hist(df$inclarge)
#hist(df$reduce)
#hist(df$reduce_large)

```
##### Temporary Fix

```{r}
df <- df %>%
  mutate(incdiff = ifelse(incdiff < 1 | incdiff > 5, NA, incdiff),
         inclarge = ifelse(inclarge < 1 | inclarge > 5, NA, inclarge),
         reduce = ifelse(reduce < 1 | reduce > 5, NA, reduce),
         reduce_large = ifelse(reduce_large < 1 | reduce_large > 5, NA, reduce_large))
```



##### Summarize by Country

Here learn about the *"pipe"* operator and coding with *dplyr* (part of 'tidyverse')

```{r c_sums}
df %>%
  select(country, reduce, reduce_large) %>% # choose variables out of df
  group_by(country) %>%
  summarise_all(list(mean, sd), na.rm = T) %>%
  arrange(-reduce_fn1) %>%
  kable(., digits = 2, col.names = c("Country","Incdiff_MEAN","Increduce_MEAN","Incdiff_SD","Increduce_SD"))

```

##### T-Test and P-Values

The surveys in these countries are samples of around 1,000 people per country per wave. Therefore, we don't know if the mean of the *sample* is exactly the same as the mean of the *population*.

It looks like the United States is less supportive of redistribution than Denmark on average. Lets use a t-test to investigate that.

We usually think of p-value as indicating if something is *significantly* different. Here we can interpret it as follows:

1. If all data are taken from *random samples*, and
2. The redistribution question missing responses are *missing at random*, and
3. The *data-generating model* is correct

Then, the p-value is the likelihood that the true mean difference between the two samples (two countries here) is *exactly zero*, this is also known as the *null hypothesis*. The lower the p-value, the less likely - known as *null hypothesis significance test* or (*NHST*).

T-tests and p-values were designed for experiments as a way to test if the control and treatment groups have different means (i.e., that they do not have a difference of zero). This is the *independent samples t-test* because we have two samples rather than the same sample compared at two different time points.

```{r ttest1}
t.test(df$reduce[df$cntry == 840],df$reduce[df$country == "Denmark"])

t.test(df$reduce[df$cntry == 840 & !is.na(df$educyrs)],df$reduce[df$cntry == 840 & is.na(df$educyrs)])

```
**TIP!** You can add equations in R markdown (help here: https://rpruim.github.io/s341/S19/from-class/MathinRmd.html)

the *t-value* formula when comparing two independent samples 

$$t = \frac {u_{A} - u_{B}} {\sqrt{(\frac {(\sum_{A^2} - \frac {(\sum_{A})^6} {n_{A}}) + (\sum_{B^2} - \frac {(\sum_{B})^6} {n_{B}})} {n_{A}+n_{B}-2}})}*(\frac{1} {n_{A}}+\frac{1} {n_{B}})$$

$(\sum_{A})^2$: Sum of group A, squared

$(\sum_{B})^2$: Sum of group B, squared

$u_{A}$: Mean of group A

$u_{B}$: Mean of group B 

$\sum_{A^2}$: Sum of the squares of data set A 

$\sum_{B^2}$: Sum of the squares of data set B 

$n_{A}$: Number of cases A

$n_{B}$: Number of cases B

Source: https://www.statisticshowto.com/probability-and-statistics/t-distribution/independent-samples-t-test/

The P-value is calculated from the T-value. 

```{r tp, out.width="150%"}
knitr::include_graphics(here::here("learning","images","SS02SDlosn1.gif"))
```
Source: https://analystnotes.com/cfa-study-notes-the-standard-normal-distribution.html

##### Regression

We can apply a regression to arrive at the same results. A regression with two intercepts, one for each country will provide the same information.

```{r ttest1_reg}
df %>%
  subset(cntry %in% c(840, 208), select = c(reduce, cntry)) %>%
  lm(reduce ~ factor(cntry), data = .) %>%
  summary()
```

##### Visualize Results

jtools package has many useful features for summarizing and visualizing regressions https://cran.r-project.org/web/packages/jtools/vignettes/summ.html

lets add a few more countries to make it interesting

```{r ttest1_viz}

df_ttest <- df %>%
  subset(country %in% c("United States", "Denmark", "Australia", "Sweden", "Japan"), select = c(reduce, country))

m1 <-  lm(reduce ~ factor(country), data = df_ttest)

plot_summs(m1, plot.distributions = T 
           #omit.coefs = F, # note that the intercept is the average of all cases in the sample
           )

```

##### Compare by Wave

Are countries really so different? We are comparing many waves (many different samples from different years). To do this we would need to verify that all years are similar.

Here is a ggplot of countries over time to help us check. We also add the standard error. Remember the formula for standard error is:

$SE =  \frac {\sigma}{\sqrt{n}}$

Where

$\sigma = \sqrt{\frac {\sum_{(x_{i} - \mu)^2}}{N}}$

This means that the larger the sample, the smaller the standard error

$N$	=	the size of the population

$x_{i}$	=	*each value from the population*

$\mu$	=	the population mean

The *residual* or *error* is the distance of the mean to each observed value and the squared error. We we talk about *sum of squares* it is the sum of the squared residual. Regression analysis seeks to minimize the sum of the squared residual, that is *ordinary least squares* estimation (*OLS*).

```{r ggplot_prep}
# add SE to summary data, and summarize by country and year
sum_table <- df %>%
  select(country, year, reduce, reduce_large) %>% # choose variables out of df
  group_by(country, year) %>%
  mutate(n = n()) %>%
  summarise_all(list(mean, sd), na.rm = T) %>%
  arrange(-reduce_fn1) %>%
  setNames(.,c("Country","Year","Incdiff_MEAN","Inclarge_MEAN","N","Incdiff_SD","Inclarge_SD","drop")) %>%
  select(-drop) %>%
  mutate(Incdiff_SE = Incdiff_SD/sqrt(N),
         Inclarge_SE = Inclarge_SD/sqrt(N))
```
```{r ggplot_plot}
sum_table %>%
  subset(Year %in% c(2009,2010)) %>%
ggplot(aes(y = Incdiff_MEAN, x = Year, color = Country)) +
  geom_point() +
  geom_line() +
  geom_errorbar(aes(ymin = Incdiff_MEAN-Incdiff_SE, ymax = Incdiff_MEAN+Incdiff_SE, width = 0.2)) +
  #geom_smooth(method = 'lm', se = F) +
  theme_classic()
```
Based on visualization:
1. How is it that Denmark changed so much in just one year (2000-2001)
2. Might not be a good idea to pool data because it is an unbalanced-'panel' of countries


##### Latent Variable

A single question is bound to leave a lot of measurement error. For example:
- People may misunderstand the question and answer it in a way that does not reflect their preference
- People may tick the wrong box on accident
- People change their preferences when asked the same question repeatedly they give different answers in the same survey or in different surveys over time
- This particular question might capture preferences for redistribution, but what is that? The words used in the question will have slightly different meanings for each respondent
- The time of day, recent life events or even the survey researcher who is speaking with them can influence responses

Therefore, having more questions that ask about a similar concept or attitude can reduce measurement error.

We assume that individuals have an attitude that can be compared across individuals - here preferences for redistribution. We cannot observe this directly because of the errors associated with survey questions. this means our target measure is a *latent variable* and we want to approximate it using *observed variables* such as multiple questions. Here we have only two, but two is better than one!

```{r scale}
# get the correlation
df %>%
  select(incdiff, inclarge) %>%
  cor(., use = "pairwise.complete.obs")

# make a scale
df <- df %>%
  mutate(
        redist = reduce + reduce_large,
        redist_scale = scale(reduce + reduce_large)
        )

hist(df$redist)


```


Lets consider how years of education impacts preferences for redistribution now. Lets look at the data first.

```{r educ_incdiff}
df %>%
  subset(country == "United States") %>%
  ggplot(aes(y = reduce, 
             x = reduce_large
             )) +
  #geom_point() +
  geom_jitter(size = 0.2) +
  stat_cor() +
  xlab("Income differences in [country] are too large") +
  ylab("Govt should reduce income differences") +
  geom_smooth(method = 'lm')

df %>%
  subset(country == "Sweden") %>%
  ggplot(aes(y = reduce, 
             x = reduce_large
             )) +
  #geom_point() +
  geom_jitter(size = 0.2) +
    stat_cor() +
  xlab("Income differences in [country] are too large") +
  ylab("Govt should reduce income differences") +
  geom_smooth(method = 'lm')

#             Same (0.05)?       USA         DNK
# Nate        Y                 0.47 1        0.52     
# Tom         N 1               0.40 1       0.51
# Hung        N 1               0.60        0.40
# Arne        N 1               0.42 2        0.55
# Soeren      N 1               0.55        0.39

```
#### Regression

Regression is really just a correlation with an intercept added. It gets more complicated in "multiple" regression where there is more than one X variable. But this is a useful way to think about it.

A regression is an algebraic attempt to populate an equation with values. 

Let's take the example hypothesis *"Does education influence preferences for redistribution?"*

We could write a simply regression formula for this hypothesis as:

$Y_{redist\_prefs} = b_{0}X_{0_{intercept}} + b_{1}X_{1_{yrs\_education}} + e_{Y_{redist\_prefs}}$

In this formula $Y_{redist\_prefs}$ is our dependent variable. Usually we think of things linearly. Therefore we want to know if there is a linear association between $Y$ and our independent variable (our 'test' variable) $X_{1_{yrs\_education}}$. A linear association is $b_{1}$. 

We want to know if $b_{1}$ is different from zero. $b_{1}$ is the slope of a line (like in the above correlation plots). A steeper slope indicates a stronger association. 

The `lm` package is the standard "linear model" package for running regressions.



```{r reg_ed_redist}

m1 <- lm(redist ~ educyrs, data = df)

summary(m1)
```

In our above equation we can now have $b_{0}$ = `r round(m1[["coefficients"]][["(Intercept)"]],3)` and $b_{1}$ = `r round(m1[["coefficients"]][["educyrs"]],3)`

How do we interpret this?


```{r z_reg_ed_redist}
m1_z <- lm(scale(redist) ~ scale(educyrs), data = df)

summary(m1_z)
```

In a single regression (just one independent variable), the standardized coefficient is roughly the same as the correlation.

```{r ed_redist_cor}
df %>%
  select(educyrs, redist) %>%
  cor(use = "pairwise.complete.obs")
```

##### R-Squared

In the regression equation above we have $e_{Y_{redist\_prefs}}$ which is the "*error term*" or "*residual*". It is everything that the intercept and independent variables cannot explain about the dependent variable. 

We can visualize this:

```{r ed_redist_r}
df$pred_m1 <- predict(m1, newdata = df)
df$resid_m1 <- df$redist - df$pred_m1
# there are far too many points in the dataframe to see in a plot
# we can take a random sample of our data

# by setting a seed we can ensure that the random sample is reproducible
set.seed(90216)

df %>%
  sample_n(5000) %>% # this takes 3000 cases randomly
  ggplot(aes(x = pred_m1, y = redist)) +
  geom_point(
    position = 'jitter', 
    size = 0.2) +
  geom_smooth(method = 'lm', se = F) + # add regression line
  stat_cor(label.y.npc = "bottom")  # add correlation to plot

```

The R-squared is the squared correlation between the predicted values of Y and the actual values of Y. 

##### Regression with Groups

We have many countries and many time points. As careful 'pedantic' social scientists, we should not assume that all groups have a similar association of $Y_{redist\_prefs}$ and $X_{1_{yrs\_education}}$.

Lets start by comparing just two countries, Germany and Sweden. 

*METHOD 1* Run two regressions

```{r groups_red_educ_redist}
m1_deu <- lm(redist ~ educyrs, data = subset(df, df$iso3c == "DEU"))
m1_swe <- lm(redist ~ educyrs, data = subset(df, df$iso3c == "SWE"))

summary(m1_deu)
summary(m1_swe)
```
```{r ex}
df %>%
  subset(iso3c %in% c("DEU", "SWE")) %>%
  ggplot(aes(x = educyrs, y = redist, color = iso3c)) +
  geom_smooth(method = 'lm', se = F) +
  coord_cartesian(xlim = c(0,10))
```



Method 1 requires us to manually compare the coefficients. We could do this with a t-test. But, we can also just run a single regression.

*METHOD 2* Single regression with different slopes

Here the regression equation would look like the following:

$Y_{redist\_prefs} = b_{0}X_{0_{intercept}} + b_{1}X_{1_{yrs\_education\_DEU}} + b_{2}X_{2_{yrs\_education\_SWE}} + e_{Y_{redist\_prefs}}$


This is most easily achieved with an interaction because X1 = 0 for the country Sweden and X2 = 0 for the country Germany

```{r groups_red_educ_redist2}
df <- df%>%
  mutate(sweden = ifelse(iso3c == "SWE",1,0),
         edu_swe = sweden*educyrs,
         edu_deu = ifelse(sweden == 0, educyrs, 0)) # make a dummy variable for Sweden

m1_deu_swe <- lm(redist ~ edu_swe + edu_deu, data = subset(df, df$iso3c %in% c("DEU","SWE")))

summary(m1_deu_swe)
```

Is this the same as running two regressions?


*METHOD 3* Single regression with two slopes and two intercepts

To achieve identical results as with the two separate regressions by country, we actually need to allow a different intercept for each country. This equation looks like:

$Y_{redist\_prefs} = b_{01}X_{0_{intercept\_DEU}} + b_{02}X_{0_{intercept\_SWE}}+ b_{11}X_{1_{yrs\_education\_DEU}} + b_{12}X_{1_{yrs\_education\_SWE}} + e_{Y_{redist\_prefs}}$

We have to be careful with this equation. Because all independent variables are added together with + signs, we cannot add both slopes from the separate equations. Instead we start with the slope for one country and then the second slope is the difference for the other country to that slope.

```{r groups_red_educ_redist3}
m1_deu_swe2 <- lm(redist ~ factor(iso3c)*educyrs, data = subset(df, df$iso3c %in% c("DEU","SWE")))

summary(m1_deu_swe2)



```

Now when we add the intercepts together we get the intercept for Sweden and we have reproduced the two separate regressoin results.

Is it a good idea to compare two countries this way? What assumption are we making?

Think about the R-squared from the two equations separately

#### Multilevel Modeling

*METHOD 5* Welcome to multilevel modeling!

We want to allow a country-specific error term, because we know that the fit of the predicted values to the actual values of Y is much better.

Now the equation looks like this:

$Y_{redist\_prefs} = b_{01}X_{0_{intercept\_DEU}} + b_{02}X_{0_{intercept\_SWE}}+ b_{11}X_{1_{yrs\_education\_DEU}} + b_{12}X_{1_{yrs\_education\_SWE}} + e_{Y_{01_{redist\_prefs\_DEU}}} + e_{Y_{02_{redist\_prefs\_SWE}}}$

```{r groups_red_educ_redist4}
m1_mlm_deu_swe <- lmer(redist ~ educyrs + (1 | iso3c) + (iso3c | educyrs), data = subset(df, df$iso3c %in% c("DEU","SWE")))

summary(m1_mlm_deu_swe)

# we can extract the coefficients and intercepts for each country

ranef(m1_mlm_deu_swe)$iso3c

```

In the summary we now have only one intercept and one slope. What this model has done is to generate an average intercept and average slope and then identifies germany and sweden as deviations from that average (these are called 'grand mean intercept' and 'grand mean slope').

There is a reason for this:


We often want to compare more groups than just two countries. And to do this like Method 4 would require a new intercept and new slope for each country. Imagine comparing 50 countries, what a crazy equation that would produce!

Instead the new equation (which can handle unlimited countries looks like this):

$Y_{ij_{redist\_prefs}} = \gamma_{00}X_{0_{intercept_{grand\_mean}}} + u_{0j}X_{0_{intercept_{j}}} + \gamma_{10_{yrs\_education_{grand\_mean\_slope}}} + u_{1j}X_{1_{yrs\_education_{j\_specific\_slope}}} + e_{ij}$

In multilevel modeling we often use $\gamma$ (gamma) instead of 'b' (beta) to represent coefficients. this is because this equation is actually the product of two equations. The errors are often listed as 'u' but we could also use gamma.

